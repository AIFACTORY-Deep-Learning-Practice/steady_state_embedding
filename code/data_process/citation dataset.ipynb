{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys\n",
    "\n",
    "data_root='../../dropbox/raw_data/citation'\n",
    "\n",
    "def parse_index_file(filename):\n",
    "    \"\"\"Parse index file.\"\"\"\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "def load_data(dataset_str):\n",
    "    \"\"\"Load data.\"\"\"\n",
    "    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(\"{}/ind.{}.{}\".format(data_root, dataset_str, names[i]), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding='latin1'))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "\n",
    "    x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "    test_idx_reorder = parse_index_file(\"{}/ind.{}.test.index\".format(data_root, dataset_str))\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "    print allx.shape, x.shape, tx.shape\n",
    "    if dataset_str == 'citeseer' or dataset_str == 'nell':\n",
    "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
    "        # Find isolated nodes, add them as zero-vecs into the right position\n",
    "        # test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
    "        test_idx_range_full = range( allx.shape[0], len(graph) )\n",
    "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
    "        tx_extended[test_idx_range-allx.shape[0], :] = tx\n",
    "        tx = tx_extended\n",
    "        ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
    "        ty_extended[test_idx_range-allx.shape[0], :] = ty\n",
    "        ty = ty_extended\n",
    "\n",
    "    features = sp.vstack((allx, tx)).tolil()\n",
    "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "    print features.shape\n",
    "    \n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "    print adj.shape\n",
    "    labels = np.vstack((ally, ty))\n",
    "    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "    idx_test = test_idx_range.tolist()\n",
    "    idx_train = range(len(y))\n",
    "    idx_val = range(len(y), len(y)+500)\n",
    "\n",
    "    train_mask = sample_mask(idx_train, labels.shape[0])\n",
    "    val_mask = sample_mask(idx_val, labels.shape[0])\n",
    "    test_mask = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "    y_train = np.zeros(labels.shape)\n",
    "    y_val = np.zeros(labels.shape)\n",
    "    y_test = np.zeros(labels.shape)\n",
    "    y_train[train_mask, :] = labels[train_mask, :]\n",
    "    y_val[val_mask, :] = labels[val_mask, :]\n",
    "    y_test[test_mask, :] = labels[test_mask, :]\n",
    "\n",
    "    return adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, idx_train, idx_val, idx_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8922, 5414) (105, 5414) (969, 5414)\n",
      "(65755, 5414)\n",
      "(65755, 65755)\n"
     ]
    }
   ],
   "source": [
    "d = 'nell'\n",
    "idxes = {}\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, idxes['idx_train'], idxes['idx_val'], idxes['idx_test'] = load_data(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8922, 5414) (105, 5414) (969, 5414)\n",
      "(65755, 5414)\n",
      "(65755, 65755)\n"
     ]
    }
   ],
   "source": [
    "d = 'nell'\n",
    "idxes = {}\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, idxes['idx_train'], idxes['idx_val'], idxes['idx_test'] = load_data(d)\n",
    "\n",
    "output_root='../../dropbox/data/%s' % d\n",
    "\n",
    "if not os.path.isdir(output_root):\n",
    "    os.makedirs(output_root)\n",
    "    \n",
    "a = features[0]\n",
    "with open('%s/features.txt' % output_root, 'w') as f:\n",
    "    for i in range(features.shape[0]):\n",
    "        row, col, val = sp.find(features[i])\n",
    "        f.write('%d' % len(col))\n",
    "        for j in range(len(col)):\n",
    "            if d == 'pubmed':\n",
    "                f.write(' %d:%.8f' % (col[j], val[j]))\n",
    "            else:\n",
    "                f.write(' %d:%.2f' % (col[j], val[j]))\n",
    "        f.write('\\n')\n",
    "        \n",
    "with open('%s/meta.txt' % output_root, 'w') as f:\n",
    "    f.write('%d %d %d\\n' % (len(train_mask), len(y_train[0]), features.shape[1]))\n",
    "\n",
    "num_label = len(y_train[0])\n",
    "with open('%s/label.txt' % output_root, 'w') as f:\n",
    "    for i in range(features.shape[0]):\n",
    "        y = None\n",
    "        if train_mask[i]:\n",
    "            y = y_train[i]\n",
    "        elif val_mask[i]:\n",
    "            y = y_val[i]\n",
    "        elif test_mask[i]:\n",
    "            y = y_test[i]\n",
    "        for j in range(num_label):\n",
    "            if y is not None:\n",
    "                f.write('%d ' % y[j])\n",
    "            else:\n",
    "                f.write('0 ')\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('%s/adj_list.txt' % output_root, 'w') as f:\n",
    "    for i in range(adj.shape[0]):\n",
    "        _, col, _ = sp.find(adj[i])\n",
    "        f.write('%d' % len(col))\n",
    "        for j in range(len(col)):\n",
    "            f.write(' %d' % col[j])\n",
    "        f.write('\\n')\n",
    "        \n",
    "for p in ['train', 'val', 'test']:\n",
    "    idx = idxes['idx_%s' % p]\n",
    "    with open('%s/%s_idx.txt' % (output_root, p), 'w') as f:\n",
    "        for i in idx:\n",
    "            f.write('%d\\n' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
